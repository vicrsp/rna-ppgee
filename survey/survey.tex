\documentclass[conference]{IEEEtran}
% If the IEEEtran.cls has not been installed into the LaTeX system files, 
% manually specify the path to it:
% \documentclass[conference]{../sty/IEEEtran} 
\usepackage[brazil]{babel}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

\begin{document}
	
	% paper title
	\title{Fundamentos de Redes Neurais Artificiais}
	
	
	% author names and affiliations
	% use a multiple column layout for up to three different
	% affiliations
	\author{\authorblockN{Victor São Paulo Ruela \\}
		\authorblockA{Programa de Pós-Graduação em Engenharia Elétrica\\
			Universidade Federal de Minas Gerais\\
			Belo Horizonte, Brasil\\
            Email: victorspruela@ufmg.br}}
	
	% avoiding spaces at the end of the author lines is not a problem with
	% conference papers because we don't use \thanks or \IEEEmembership
	
	% use only for invited papers
	%\specialpapernotice{(Invited Paper)}
	
	% make the title area
	\maketitle
	
	\begin{abstract}
		Este trabalho tem como objetivo apresentar uma revisão da literatura de redes neurais aritificiais, com enfoque na evoluções das principais técnicas clássicas. 
	\end{abstract}

	\section{Introdução}
	A Redes Neural Artificial (RNA) é uma classe de modelos muito popular em problemas de classificação, reconhecimento de padrões, regressão e predição \cite{jain1996artificial}. Inspirado pelas características do cérebro humano, elas possuem como elementos básicos neurônios artificiais capazes de executar operações matemáticas, representando desta forma modelos de neurônios biológicos. Através de sua organização em diferentes estruturas de rede, tais modelos são capazes de se adaptar e representar funções matemáticas bastante complexas. 
	
	Diferentes representações estão presentes na literatura, as quais são classificadas de acordo com o seu nível de complexidade e requisitos coputacionais de implementação. Hipóteses básicas para regras de aprendizado de associações entre neurônios podem ser encontradas em trabalhos bastante antigos, como abordado no livro de William James em 1982 \cite{james1984psychology}. Entretanto, um grande marco desta área de pesquisa ocorreu na década de 40 após a introdução do modelo de McCulloch and Pitts (MCP) \cite{mcculloch1943logical}, o qual é a adotado atualmente nos principais modelos de RNAs.
	
	O modelo MCP tem como saída a soma das ativações dos neurônios anteriores ponderados pelos pesos das conexões entre eles. Uma função de ativação do tipo degrau é aplicada sobre esta saída, configurando modelo de soma-e-limiar originalmente descrito pelos autores. Este trabalho apresentou a configuração de diversas redes de neurônios MCP, com enfoque na implementação de funções lógicas. Vale a pena notar que os primeiros computadores digitais estavam surgindo nesta época, motivando esta aplicação. Entretanto, as estruturas apresentadas eram estáticas e não houve a sugestão de algum método de aprendizado para adaptá-las,
	
	O aprendizado surgiu de forma mais concreta com o postulado de Hebb \cite{hebb2005organization}, originalmente publicado em 1949. De acordo com o autor, a eficiência de uma determinada sinapse que conecta dois neurônios é proporcional à co-ocorrência de ativação entre eles. Portanto, o princípio de aprendizado Hebbiano visa reforçar as conexões relevantes para as diferentes saída da rede, guiado pela correlação entre os neurônios. 
	
	A partir destes princípios elementares, a área de RNAs evoluiu bastante nas últimas décadas. Após a introdução das primeiras regras de aprendizado, este tipo de modelo ganhou maior visibilidade e aplicabilidade para problemas reais, sendo possível encontrar uma enorme quantidade de aplicações publicadas \cite{abiodun2018state}. Além disso, o aumento dos recursos computacionais disponíveis fomentou o desenvolvimento de novas técnicas para aprendizado e o aprimoramento das existentes, além de propostas de novas estruturas redes complexas capazes de lidar com problemas de grande dificuldade.
	
	Portanto, o objetivo deste trabalho é apresentar a uma revisão da literatura contendo os principais trabalhos que levarama à evolução dos diferentes modelos de redes neurais presentes no dia de hoje. Partindo das referências clássicas, diferentes abordagens propostas serão analisadas de forma cronológica como forma de se entender a evolução desta área de pesquisa até o tempo presente. 
		
	
%	\subsection{Problemas de classificação}
%	A tarefa de classificação consiste em associar um conjunto de padrões de entrada, representado por um vetor de características, para uma de varias classes previamente definidas.

%	\subsection{Problemas de regressão}
%	Dado um conjunto de $N$ pares de dados de entrada-saída $\left\lbrace (\mathbf{x}_1, y_1), \dots, (\mathbf{x}_N, y_N)\right\rbrace$, o objetivo da regressão é encontrar uma função aproximada $\hat{f}(\mathbf{x})$ que melhor descreve a função desconhecida $f(\mathbf{x})$ utilizada para gerar estes dados.
%
%	\subsection{Problemas de predição}
%	Considerando um conjunto de $N$ $\left\lbrace y(t_1),\dots, y(t_N) \right\rbrace $ amostras ordenadas em função do instande de tempo em que foram amostradas $t_1, \dots, t_N$, o objetivo da predição é estimar qual será o valor da amostra $y_{N+1}$ em um tempo futuro $t_{N+1}$.
%
%	\subsection{Problemas de reconhecimento de padrões}
	
	\section{Aprendizado supervisionado}
	RNAs de aprendizado supervisionado são responsáveis pela inferência de uma função desconhecida $f(.)$ que realiza o mapeamento entre uma saída e um conjunto de entradas medidas, representada pelo conjunto de $N$ pares de dados $\mathcal{D} = \left\lbrace (\mathbf{x}_1, y_1), \dots, (\mathbf{x}_N, y_N)\right\rbrace $. Problemas de classificação e regressão são comumente solucionados com estas técnicas, para os quais as primeiras estruturas de rede e algoritmos de treinamento descritos na literatura são o \textit{Adaline}, em 1960, e o Perceptron simples, em 1957. 

	\subsection{Adaline}	

	\subsection{Perceptron}
	Proposto inicialmente por Rosenblatt \cite{rosenblatt1957perceptron}, este é um modelo geralmente utilizado para a solução de problemas de classificação. No seu trabalho original, o autor descreve formas de adaptação dos parâmetros, ou pesos, da rede com o objetivo de reduzir a discrepância entre as saídas esperadas e estimadas e aprender associações entre os neurônios, o que é a base da indução para diversos algoritmos atuais. Este trabalho é considerado um marco na literatura por diversos autores.
	
	Embora descrito como uma rede de duas camadas, originalmente seu treinamento só considerava uma camada. Por esse motivo, o Perceptron simples é comumente descrito na forma de somente um neurônio MCP. Sua regra de aprendizado é bem direta e consiste em alterar iterativamente os pesos da rede de acordo com a seguinte regra:
	\begin{equation}
		\mathbf{w}(k+1) = \mathbf{w}(k) + \eta e(k) \mathbf{x}(k)
	\end{equation}
	onde $\mathbf{x}(k)$, $e(k)$ e $\mathbf{x}(k)$ são o vetor de pesos, o erro e o vetor de entradas na $k$-ésima iteração do treinamento, respectivamente. A constante $\eta$ é um escalar utilizado para controlar o tamanho do passo em cada iteração. 
	
	Se considerarmos uma função de ativação contínua e diferenciável, os pesos da rede poderão ser inferidos de forma explícita, através do cálculo da pseudo-inversa, ou pelo algoritmo do gradiente descendente \cite{hertz1991introduction}, similar à regra delta introduzida pelo Adaline. Exemplos de funções de ativação com esta característica frequentemente empregadas na literatura são a sigmoidal, tangente hiperbólica e linear. Vale a pena ressaltar que a covergência destas abordagens está condicionada aos dados utilizados para treinamento serem linearmente independentes \cite{hertz1991introduction}.
		
	Rosenblatt provou a convergência da regra de aprendizado original, porém a mesma só é garantida para problemas linearmente separáveis \cite{minsky1969introduction}, o que constitui a principal limitação deste modelo. Após este trabalho, Rosenblatt avaliou diferentes arquiteturas de rede tentando superar esta limitação, porém não chegou ao desenvolvimento de uma regra para aprendizado dos pesos. Por conta disso, o Perceptron foi pouco estudado pelos próximos de 20 anos \cite{hertz1991introduction}.
	
	O interesse pelo Perceptron retornou na década de 80 com a descrição do método de aprendizado conhecido como \textit{back-propagation}, o qual é capaz de aprender os pesos de redes de múltiplas de forma eficiente \cite{rumelhart1985learning}. Aliado a isso, o Perceptron de múltiplas camadas é capaz de descrever superfícies de separação não-lineares, superando a pricipal limitação do trabalho de Rosenblatt. Uma descrição mais completa desta técnica é feita na próxima seção.
	
	
%	\begin{enumerate}
%		\item Inicializar os parâmetros da rede com valores aletórios
%		\item 
%	\end{enumerate}
	
	\subsection{Perceptron de múltiplas camadas}
	

	\subsection{Máquinas de aprendizado extremo}
	\subsection{Redes RBF}

	\subsection{Máquinas de vetores suporte}
	\subsection{Aprendizado multiobjetivo}
	\section{Aprendizado não-supervisionado}
	\subsection{Aprendizado Hebbiano}
	\subsection{SOM}

%	\section{Aprendizado semi-supervisionado}

%	\section{Generalização}
%	 Uma das suas principais características do modelo RNA é sua capacidade de generalização.  Em geral, algoritmos de aprendizado supervisionado possuem como objetivo minimizar o erro quadrático dos valores previstos pelo modelo em relação às saídas em estudo:
%	 \begin{equation}
%	 	\sum_{i=1}^{N} [y_i - f(\mathbf{x}_i)]^2
%	 	\label{eq:sqrd}
%	 \end{equation}
%	 onde $y_i$ é uma resposta desejada para uma entrada $\mathbf{x}_i$, e $f$ é o função que aproxima a resposta desejada. Ou seja, estamos interessados em encontrar o conjunto de pesos $\mathbf{w}$ da rede a partir dos pares de dados de entrada-saída $\mathcal{D} = \left\lbrace (\mathbf{x}_1, y_1), \dots, (\mathbf{x}_N, y_N)\right\rbrace $ que melhor aproxima a função desconhecida $f$.
%	 
%	 Entretanto, se os dados a serem modelados são ruidosos o uso deste único objetivo pode levar a um overfitting sobre o conjunto de dados de treinamento, de forma que este não consiga generalizar bem para novos valores observados. Estatisticamente, podemos definir a efetividade de $f$ como um estimador de $y$ como \cite{geman1992neural}:
%	 
%	 \begin{equation}
%	 	\begin{aligned}
%	 		E[(y - f(\mathbf{x}; \mathcal{D}))^2 | \mathbf{x}, \mathcal{D}] \quad = & \quad E\left[ (y - E \left[ y | \mathbf{x}\right] )^2 | \mathbf{x}, \mathcal{D}\right]   \\
%	 		& \quad + (f(\mathbf{x};\mathcal{D}) - E[y|\mathbf{x}])^2
%	 	\end{aligned}
%	 \end{equation}
%	 
%	 É importante notar neste indicador que o primeiro termo representa a variância de $y$ dado $\mathbf{x}$, não dependendo dos dados. Já o segundo termo mede a distância entre o estimador e a regressão. Logo, podemos definir o error quadrático médio de $f$ como um estimador da regressão $E[y|\mathbf{x}]$ para um conjunto de dados $\mathcal{D}$ como:
%	 
%	 \begin{equation}
%	 	\begin{aligned}
%	 		& E_{\mathcal{D}}[(f(\mathbf{x};\mathcal{D}) - E[y|\mathbf{x}])^2] = \\ 
%	 		& \qquad \qquad \qquad (E_{\mathcal{D}}[f(\mathbf{x}; \mathcal{D})] - E[y|\mathbf{x}])^2 \quad \text{``viés''} \\
%	 		& \qquad \quad  + E_{\mathcal{D}}\left[ f(\mathbf{x};\mathcal{D}) - E_{\mathcal{D}}[f(\mathbf{x};\mathcal{D})]\right]   \quad \text{``variância''}
%	 	\end{aligned}
%	 \end{equation}
%	 A derivação completa da relação acima pode ser encontrada em \cite{geman1992neural}. Logo é fácil notar que o aprendizado de RNAs é um problema multi-objetivo, no qual precisamos encontrar uma solução de compromisso entre o viés e a variância do modelo. Portanto, em um dos extremos teremos um conjunto de pesos que resultam em um viés máximo (\textit{underfitting}) e no outro variância máxima (\textit{overfitting}).
	 
	\subsection{Máquinas de Vetores Suporte}
	\subsection{Aprendizado Multiobjetivo}


	
    \bibliographystyle{unsrt}
	\bibliography{survey}
	
\end{document} 